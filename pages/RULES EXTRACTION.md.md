It is necessary to understand which of the previously generated frequent itemsets generate rules.
Given a frequent itemset of size k , we can obain $2^k-2$ association rules from it (N.B: we remove L->0 and 0->L).

We want to look for a rule like:

*"Given X and Y-X, then X->(Y-X) has conficence $>=$ minConf"*

Confidence isn't non-monotonic, so it's not said that if a rule has more elements than another rule, it also has greater confidence.
If two rules are generated by the same itemset, then we have non-monotony, so:

***"If the rule X->Y-X is <= minConf, then X'->Y-X' (X' âŠ† X ) is <= minConf"***

### APRIORI GENERATION

1) All the frequent itemsets are scanned;
2) for each frequent itemset all the rules with a single element in the right side are generated;
3) then, the merge two by two of these rules is done, obtaining rules with two element on the right side;
4) the apriori generation continues untill the end.

We obtain a graph structure in which if a upper rule has low confidence, then every rule that comes from the upper one has same confidence and can be eliminated.

### MULTIPLE MINIMUM SUPPORT

Often a single support treshold is not enough in order to guarantee a valid tradeoff between reducing the itemset number and maximizing their quality. For this, support thresholds are defined for each possible element. Itemset's *minSup* will be given by the minimum *minSup* value of its items.
- Once defined the *minSup* value for each item, *minSup* values are sorted by ascending order.
- Then, the possible itemsets are generated up to the order k and the ones contining the first element, that is the minimum minSup, are pruned.

### EVALUATING PATTERNS

Associative mining algorithms produce tons of rules that can be redundant or not so important. We need methods to evaluate and sort rules according to their interest grade.

A very used methos to evaluate the grade of interest of a rule is based on contingency tables, where the negated value says that the itemset X is not present in the transaction.
					![](Pasted%20image%2020231231184704.png)

##### - PROBABILISTIC OPERATORS
A rule with high confidence can have low lift if both sides of the rule are frequent, the same applies in the opposite case.
						![](Pasted%20image%2020231231184845.png)

##### - FACTORS OF INTEREST
![](Pasted%20image%2020231231184954.png)

##### - CORRELATION
![](Pasted%20image%2020231231185032.png)


### PROPERTIES OF A GOOD MEASURE
- M(A,B)=0 if and only if A and B are statistically independent;
- M(A,B) grows monotously with P(A,B), while P(A) and P(B) remain unchanged;
- M(A,B) decreases monotously with P(A) while P(A,B) and P(B) remain unchanged;
- association rules should be independent from the relative sample elements' number.